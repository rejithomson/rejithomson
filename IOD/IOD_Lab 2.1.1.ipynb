{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PopLE1ywNQsa"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e45O_NedNQsd"
   },
   "source": [
    "# Lab 2.1.1 \n",
    "# *Data Wrangling and Munging with Pandas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qr08YR1PNQsf"
   },
   "source": [
    "## Part 1: Wrangling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RH9yA6LINQsh"
   },
   "source": [
    "The term \"data wrangling\" is analogous to capturing wild horses and getting them into a fenced area; the horses are data and the fencing is your computer. The more common data wrangling tasks include:\n",
    "\n",
    "- reading flat files\n",
    "- reading Excel files\n",
    "- downloading from web pages\n",
    "  - csv\n",
    "  - html\n",
    "  - json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baKB6_WIBp_8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8G9iecYNQsr"
   },
   "source": [
    "*It is good practice to display the library version numbers for future reference:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MC0XSmScBqAD",
    "outputId": "c6f51e70-1f8e-412c-b320-b370e38f2a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy:  1.17.2\n",
      "Pandas:  0.25.1\n"
     ]
    }
   ],
   "source": [
    "print('Numpy: ', np.__version__)\n",
    "print('Pandas: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzTKAG1LNQsx"
   },
   "source": [
    "### CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RE2wYKPNNQsy"
   },
   "source": [
    "Below are three attempts to load the file \"bikeshare.csv\" into a DataFrame named `bikes`. Why are they wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZV2HMWarNQsz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0       1        2           3        4      5   \\\n",
      "0                 datetime  season  holiday  workingday  weather   temp   \n",
      "1      2011-01-01 00:00:00       1        0           0        1   9.84   \n",
      "2      2011-01-01 01:00:00       1        0           0        1   9.02   \n",
      "3      2011-01-01 02:00:00       1        0           0        1   9.02   \n",
      "4      2011-01-01 03:00:00       1        0           0        1   9.84   \n",
      "...                    ...     ...      ...         ...      ...    ...   \n",
      "10882  2012-12-19 19:00:00       4        0           1        1  15.58   \n",
      "10883  2012-12-19 20:00:00       4        0           1        1  14.76   \n",
      "10884  2012-12-19 21:00:00       4        0           1        1  13.94   \n",
      "10885  2012-12-19 22:00:00       4        0           1        1  13.94   \n",
      "10886  2012-12-19 23:00:00       4        0           1        1  13.12   \n",
      "\n",
      "           6         7          8       9           10     11  \n",
      "0       atemp  humidity  windspeed  casual  registered  count  \n",
      "1      14.395        81          0       3          13     16  \n",
      "2      13.635        80          0       8          32     40  \n",
      "3      13.635        80          0       5          27     32  \n",
      "4      14.395        75          0       3          10     13  \n",
      "...       ...       ...        ...     ...         ...    ...  \n",
      "10882  19.695        50    26.0027       7         329    336  \n",
      "10883  17.425        57    15.0013      10         231    241  \n",
      "10884   15.91        61    15.0013       4         164    168  \n",
      "10885  17.425        61     6.0032      12         117    129  \n",
      "10886  16.665        66     8.9981       4          84     88  \n",
      "\n",
      "[10887 rows x 12 columns]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dat/bikeshare.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ca7fa705e513>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# wrong:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mbikes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dat/bikeshare.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbikes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_table\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dat/bikeshare.csv'"
     ]
    }
   ],
   "source": [
    "# wrong:\n",
    "bikes = pd.read_csv('bikeshare.csv', header = None)\n",
    "print(bikes)\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('dat/bikeshare.csv', header = 1)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('dat/bikeshare.csv', header = 0)\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSiMJN9NNQs4"
   },
   "source": [
    "?:\n",
    "ANSWER: Case 1 treats headings as just another data row. Case 2 treats the 1st data row as the column header. Case 3 gets the header right (row 0), but reads each row as a single column (Nb. the other two make that same mistake). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDFYVoPINQs6"
   },
   "source": [
    "Load the file \"bikeshare.csv\" into a DataFrame named `bikes`, and confirm that it was loaded properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wH2wuPznNQs8",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bikeshare.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8b103eeb124b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#ANSWER:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbikes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bikeshare.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbikes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bikeshare.csv'"
     ]
    }
   ],
   "source": [
    "#ANSWER:\n",
    "bikes = pd.read_csv('bikeshare.csv', header = None)\n",
    "print(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEwczD29NQtA"
   },
   "source": [
    "Note that we could have used `read.csv()` above. When is `read_table()` necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OsmNWLXNQtB"
   },
   "source": [
    "?:\n",
    "ANSWER: When `sep` is not the comma character, or we need fine control that `read.csv()` does not provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pPEoeHGGNQtC"
   },
   "source": [
    "Flat files can be full of surprises. Here are some issues to watch out for:\n",
    "\n",
    "- separator character is something other than the comma\n",
    "  - \";\", \"|\", and tab are popular\n",
    "- newline character is something other than what the O/S expects \n",
    "  - Tip: Don't hard-code the character codes for carriage returns, linefeeds, etc. Use Python's built-in representation instead (e.g. Python translates \"\\n\" to the newline character and \"\\t\" to the tab character on any O/S).\n",
    "- truncated lines\n",
    "  - if there are empty fields at the end of a line it is possible that their separators will be missing, resulting in a \"jagged\" file\n",
    "- embedded commas or quotes\n",
    "  - a free-text field containing embedded commas may split into separate fields on input\n",
    "  - a free-text field containing embedded quotes may not parse correctly\n",
    "- unescaped characters\n",
    "  - the \"\\\" character indicates a control code to Python, which will break the I/O\n",
    "    - e.g. the substring \"\\u0123\" will be interpreted as Unicode(0123) -- which may not be what the file creator intended\n",
    "  - these may need to be fixed by loading whole strings and then parsing into a new data frame\n",
    "  \n",
    "Tip: Most issues can be delth with by correctly specifying the parameters of the function you use to load the file. Read the doco before reading the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0G5PtA2NQtC"
   },
   "source": [
    "### Reading Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYELgCw6NQtD"
   },
   "outputs": [],
   "source": [
    "from pandas import ExcelFile  # Nb. Need to install xlrd from conda (it does not automatically install with pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDjzKP6nNQtF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sepal Length (cm)</th>\n",
       "      <th>Sepal Width (cm)</th>\n",
       "      <th>Petal Length (cm)</th>\n",
       "      <th>Petal Width (cm)</th>\n",
       "      <th>Class</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>alpha</th>\n",
       "      <th>obj</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sepal Length (cm)  Sepal Width (cm)  Petal Length (cm)  \\\n",
       "0         NaN                7.0               3.2                4.7   \n",
       "1         NaN                6.4               3.2                4.5   \n",
       "2         NaN                6.9               3.1                4.9   \n",
       "3         NaN                5.5               2.3                4.0   \n",
       "4         NaN                6.5               2.8                4.6   \n",
       "\n",
       "   Petal Width (cm)            Class  Unnamed: 6  Unnamed: 7  alpha  obj  \\\n",
       "0               1.4  Iris-versicolor         NaN         0.0    0.0  0.0   \n",
       "1               1.5  Iris-versicolor         NaN         0.0    NaN  NaN   \n",
       "2               1.5  Iris-versicolor         NaN         0.0    NaN  NaN   \n",
       "3               1.3  Iris-versicolor         NaN         0.0    NaN  NaN   \n",
       "4               1.5  Iris-versicolor         NaN         NaN    NaN  NaN   \n",
       "\n",
       "   Unnamed: 10  Unnamed: 11  \n",
       "0            0            1  \n",
       "1            0            1  \n",
       "2            0            1  \n",
       "3            0            1  \n",
       "4            0            1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Iris.xls', sheet_name = 'Iris', header =(1)) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0a2XhAZNQtH"
   },
   "source": [
    "So, this file appears to have an embedded table of aggregates on the same sheet as the raw data (a naughty but common practice amongst analysts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjWx-Xo0NQtH"
   },
   "source": [
    "It is usually better to load data correctly than to meddle with the source file or load it 'warts and all' and then try to parse it in code. The Pandas functions for reading files have parameters that provide the control we need. For ecxample, we could make multiple calls to `read_excel()`, using combinations of the `header`, `usecols`, `skiprows`, `nrows`, and `skipfooter` parameters to load one table at a time from a spreadsheet with multiple tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tC5kzTsMNQtI"
   },
   "source": [
    "Load the above file without the unwanted columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-P70uSXsNQtI"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTkOz1KsNQtK"
   },
   "source": [
    "### Importing Data Directly from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFHi_S4fNQtK"
   },
   "source": [
    "We usually want to store a local copy of a data file that we download from the Web, but when data retention is not a priority it is convenient to download the data directly into our running Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jS7P3oXQNQtL"
   },
   "source": [
    "#### Importing Text Files from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-hzkxRRNQtL"
   },
   "source": [
    "The web is the 'wild west' of data formats. However, we can usually expect good behaviour from files that are automatically generated by a service, such as the earthquake report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFuaZ82hNQtM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-17T00:59:52.702Z</td>\n",
       "      <td>-21.728800</td>\n",
       "      <td>-68.557100</td>\n",
       "      <td>148.35</td>\n",
       "      <td>4.70</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>1.10300</td>\n",
       "      <td>0.54</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-07-17T01:17:40.040Z</td>\n",
       "      <td>89 km NNE of Calama, Chile</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.138</td>\n",
       "      <td>16</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-17T00:53:25.018Z</td>\n",
       "      <td>-56.125700</td>\n",
       "      <td>-27.850300</td>\n",
       "      <td>94.71</td>\n",
       "      <td>5.60</td>\n",
       "      <td>mww</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "      <td>5.28000</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-07-17T01:12:01.675Z</td>\n",
       "      <td>South Sandwich Islands region</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>8.80</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.089</td>\n",
       "      <td>12</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-17T00:45:35.290Z</td>\n",
       "      <td>44.472832</td>\n",
       "      <td>-110.325668</td>\n",
       "      <td>8.40</td>\n",
       "      <td>3.37</td>\n",
       "      <td>ml</td>\n",
       "      <td>25.0</td>\n",
       "      <td>106</td>\n",
       "      <td>0.25420</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-07-17T00:49:27.440Z</td>\n",
       "      <td>63 km SSE of Mammoth, Wyoming</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.340</td>\n",
       "      <td>16</td>\n",
       "      <td>automatic</td>\n",
       "      <td>uu</td>\n",
       "      <td>uu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-17T00:44:54.100Z</td>\n",
       "      <td>38.539833</td>\n",
       "      <td>-119.453667</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>3.46</td>\n",
       "      <td>ml</td>\n",
       "      <td>18.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.03750</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-07-17T01:16:12.273Z</td>\n",
       "      <td>29km SSW of Smith Valley, NV</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.412</td>\n",
       "      <td>25</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-17T00:32:54.840Z</td>\n",
       "      <td>38.480667</td>\n",
       "      <td>-119.512497</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.02</td>\n",
       "      <td>ml</td>\n",
       "      <td>22.0</td>\n",
       "      <td>83</td>\n",
       "      <td>0.02888</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-07-17T01:18:10.908Z</td>\n",
       "      <td>32km ENE of Dardanelle, CA</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.459</td>\n",
       "      <td>17</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time   latitude   longitude   depth   mag magType  \\\n",
       "0  2021-07-17T00:59:52.702Z -21.728800  -68.557100  148.35  4.70      mb   \n",
       "1  2021-07-17T00:53:25.018Z -56.125700  -27.850300   94.71  5.60     mww   \n",
       "2  2021-07-17T00:45:35.290Z  44.472832 -110.325668    8.40  3.37      ml   \n",
       "3  2021-07-17T00:44:54.100Z  38.539833 -119.453667   -0.49  3.46      ml   \n",
       "4  2021-07-17T00:32:54.840Z  38.480667 -119.512497    2.93  3.02      ml   \n",
       "\n",
       "    nst  gap     dmin   rms  ...                   updated  \\\n",
       "0   NaN   54  1.10300  0.54  ...  2021-07-17T01:17:40.040Z   \n",
       "1   NaN   46  5.28000  0.91  ...  2021-07-17T01:12:01.675Z   \n",
       "2  25.0  106  0.25420  0.34  ...  2021-07-17T00:49:27.440Z   \n",
       "3  18.0   72  0.03750  0.09  ...  2021-07-17T01:16:12.273Z   \n",
       "4  22.0   83  0.02888  0.06  ...  2021-07-17T01:18:10.908Z   \n",
       "\n",
       "                           place        type horizontalError depthError  \\\n",
       "0     89 km NNE of Calama, Chile  earthquake            6.20       6.60   \n",
       "1  South Sandwich Islands region  earthquake            8.80       6.20   \n",
       "2  63 km SSE of Mammoth, Wyoming  earthquake            0.73       1.82   \n",
       "3   29km SSW of Smith Valley, NV  earthquake            0.22       0.60   \n",
       "4     32km ENE of Dardanelle, CA  earthquake            0.20       0.26   \n",
       "\n",
       "   magError  magNst     status  locationSource magSource  \n",
       "0     0.138      16   reviewed              us        us  \n",
       "1     0.089      12   reviewed              us        us  \n",
       "2     0.340      16  automatic              uu        uu  \n",
       "3     0.412      25  automatic              nc        nc  \n",
       "4     0.459      17  automatic              nc        nc  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_hour.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGgcXCzyNQtN"
   },
   "source": [
    "#### Importing HTML Files from the Web\n",
    "\n",
    "Working with unstructured HTML files relies heavily on library functions. This one, however, is well-structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4oVabZ6NQtO"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/'\n",
    "\n",
    "df = pd.read_html(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaWhHAk9NQtQ"
   },
   "source": [
    "#### Importing XML Files from the Web\n",
    "\n",
    "XML files are semi-structured, but you're at the mercy of the file creator. If every record has the same format it will be much easier, but practical applications often require a lot of custom code. Here is an example that includes a nice parser class: http://www.austintaylor.io/lxml/python/pandas/xml/dataframe/2016/07/08/convert-xml-to-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ppLnAmKVNQtQ"
   },
   "source": [
    "#### Importing JSON Files from the Web\n",
    "\n",
    "Like XML, JSON files are semi-structured and may require work to capture the schema into a dataframe. Here is a simple example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8VB9EoRrNQtS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integer</th>\n",
       "      <th>datetime</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2015-01-01 00:00:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2015-01-01 00:00:03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2015-01-01 00:00:04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   integer            datetime  category\n",
       "0        5 2015-01-01 00:00:00         0\n",
       "1        5 2015-01-01 00:00:01         0\n",
       "2        9 2015-01-01 00:00:02         0\n",
       "3        6 2015-01-01 00:00:03         0\n",
       "4        6 2015-01-01 00:00:04         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df = pd.read_json(url, orient = 'columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIArBrFFNQtV"
   },
   "source": [
    "## Part 2: Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aFUJrhENQtW"
   },
   "source": [
    "Data munging is manipulating data to get it into a form that we can start running analyses on (which usually means getting the data into a DataFrame). Before we get to this stage, we may need to remove headers or footers, transpose columns to rows, split wide data tables into long ones, and so on. (Nb. Excel files can be particularly troublesome, because users can format their data in mixed, complex shapes.) Essentially, we need to follow Hadley Wickham's guidelines for tidy datasets (http://vita.had.co.nz/papers/tidy-data.html):\n",
    "\n",
    "The end goal of the cleaning data process:\n",
    "\n",
    "- each variable should be in one column\n",
    "- each observation should comprise one row\n",
    "- each type of observational unit should form one table\n",
    "- include key columns for linking multiple tables\n",
    "- the top row contains (sensible) variable names\n",
    "- in general, save data as one file per table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kmjox61xNQtW"
   },
   "source": [
    "### Dataset Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29PQdqUMNQtX"
   },
   "source": [
    "Once we have our dataset in a DataFrame (or Series, if our data is only 1-dimensional), we can start examining its size and content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04lspVeiNQtY"
   },
   "source": [
    "How many rows and columns are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkO6SxSmNQtY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10887"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "len(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "camJWA-DNQta"
   },
   "source": [
    "What are the column names in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDzIHgjXNQtb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "len(bikes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count']\n"
     ]
    }
   ],
   "source": [
    "colnames = list(bikes)\n",
    "print(colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iL7Cm_4NNQtc"
   },
   "source": [
    "What are the data types of these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LtKQtrdSNQtd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "list(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqHDi7_GNQtf"
   },
   "source": [
    "What is the (row) index for this DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7WciAwrNQtf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datetime</td>\n",
       "      <td>season</td>\n",
       "      <td>holiday</td>\n",
       "      <td>workingday</td>\n",
       "      <td>weather</td>\n",
       "      <td>temp</td>\n",
       "      <td>atemp</td>\n",
       "      <td>humidity</td>\n",
       "      <td>windspeed</td>\n",
       "      <td>casual</td>\n",
       "      <td>registered</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>2012-12-19 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.58</td>\n",
       "      <td>19.695</td>\n",
       "      <td>50</td>\n",
       "      <td>26.0027</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>2012-12-19 20:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.76</td>\n",
       "      <td>17.425</td>\n",
       "      <td>57</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>10</td>\n",
       "      <td>231</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>2012-12-19 21:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.94</td>\n",
       "      <td>15.91</td>\n",
       "      <td>61</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>4</td>\n",
       "      <td>164</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>2012-12-19 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.94</td>\n",
       "      <td>17.425</td>\n",
       "      <td>61</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>12</td>\n",
       "      <td>117</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>2012-12-19 23:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.12</td>\n",
       "      <td>16.665</td>\n",
       "      <td>66</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10887 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0       1        2           3        4      5   \\\n",
       "0                 datetime  season  holiday  workingday  weather   temp   \n",
       "1      2011-01-01 00:00:00       1        0           0        1   9.84   \n",
       "2      2011-01-01 01:00:00       1        0           0        1   9.02   \n",
       "3      2011-01-01 02:00:00       1        0           0        1   9.02   \n",
       "4      2011-01-01 03:00:00       1        0           0        1   9.84   \n",
       "...                    ...     ...      ...         ...      ...    ...   \n",
       "10882  2012-12-19 19:00:00       4        0           1        1  15.58   \n",
       "10883  2012-12-19 20:00:00       4        0           1        1  14.76   \n",
       "10884  2012-12-19 21:00:00       4        0           1        1  13.94   \n",
       "10885  2012-12-19 22:00:00       4        0           1        1  13.94   \n",
       "10886  2012-12-19 23:00:00       4        0           1        1  13.12   \n",
       "\n",
       "           6         7          8       9           10     11  \n",
       "0       atemp  humidity  windspeed  casual  registered  count  \n",
       "1      14.395        81          0       3          13     16  \n",
       "2      13.635        80          0       8          32     40  \n",
       "3      13.635        80          0       5          27     32  \n",
       "4      14.395        75          0       3          10     13  \n",
       "...       ...       ...        ...     ...         ...    ...  \n",
       "10882  19.695        50    26.0027       7         329    336  \n",
       "10883  17.425        57    15.0013      10         231    241  \n",
       "10884   15.91        61    15.0013       4         164    168  \n",
       "10885  17.425        61     6.0032      12         117    129  \n",
       "10886  16.665        66     8.9981       4          84     88  \n",
       "\n",
       "[10887 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "pd.DataFrame(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIJcLnsKNQth"
   },
   "source": [
    "https://www.dataquest.io/blog/python-json-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtxBEejpNQti"
   },
   "source": [
    "## Slicing and Dicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tzns_pFsNQtj"
   },
   "source": [
    "It is often preferable to refer to DataFrame columns by name, but there is more than one way to do this. \n",
    "Do `bikes['season']` and `bikes[['season']]` give the same object? Demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSlC2oZXNQtj"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsCATb2iNQtl"
   },
   "source": [
    "How would we use object notation to show the first 4 rows of `atemp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5D_UU5KNQtm"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWKI9FNDNQto"
   },
   "source": [
    "Algorithms that loop over multiple columns often access DataFrame columns by index. However, none of the following work (try them out by uncommenting / removing the \"#E: \" ): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgWFEEmWNQto"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>2012-12-19 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>2012-12-19 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>2012-12-19 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>2012-12-19 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>2012-12-19 23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10887 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "0                 datetime\n",
       "1      2011-01-01 00:00:00\n",
       "2      2011-01-01 01:00:00\n",
       "3      2011-01-01 02:00:00\n",
       "4      2011-01-01 03:00:00\n",
       "...                    ...\n",
       "10882  2012-12-19 19:00:00\n",
       "10883  2012-12-19 20:00:00\n",
       "10884  2012-12-19 21:00:00\n",
       "10885  2012-12-19 22:00:00\n",
       "10886  2012-12-19 23:00:00\n",
       "\n",
       "[10887 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes[[0]]\n",
    "#E: bikes[0]\n",
    "#E: bikes[0,0]\n",
    "#E: bikes[[0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeUJ7D5qNQtq"
   },
   "source": [
    "What is the correct way to access the 1st row of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4Kidzz0NQtq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
      "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
      "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
      "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
      "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
      "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
      "\n",
      "   humidity  windspeed  casual  registered  count  \n",
      "0        81        0.0       3          13     16  \n",
      "1        80        0.0       8          32     40  \n",
      "2        80        0.0       5          27     32  \n",
      "3        75        0.0       3          10     13  \n",
      "4        75        0.0       0           1      1  \n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "\n",
    "#row1 =df.iloc[1]\n",
    "#print(row1)\n",
    "\n",
    "bikes = pd.read_csv('bikeshare.csv')\n",
    "row1 = bikes.iloc[0:5]\n",
    "print(row1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZa1v-2jNQts"
   },
   "source": [
    "What is the correct way to access the 2nd column of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4GmE0EsNQtt"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSvqNbVUNQtu"
   },
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRPFEN1HNQtu"
   },
   "source": [
    "What is the Pandas `isnull` function for? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xyw5qkWWNQtu"
   },
   "source": [
    "?\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iby8s2VSNQtv"
   },
   "source": [
    "We can apply `isnull` to the `bikes` DataFrame to show the result for every element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRQY-1ViNQtv"
   },
   "outputs": [],
   "source": [
    "bikes.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IyZaICINQtw"
   },
   "source": [
    "However, we usually start at a higher level. How many nulls are in `bikes` altogether?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbDfiSqVNQtx"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "10jWUf4VNQty"
   },
   "source": [
    "If this result were nonzero we would next want to find out which columns contained nulls. How can this be done in one line of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBv3l_s2NQtz"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n",
    "bikes.season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1MsvXf7NQt0"
   },
   "source": [
    "What is the Numpy object `nan` used for? (Write a descriptive answer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaeGVh6ZNQt0"
   },
   "source": [
    "?\n",
    "ANSWER: Marking a data point as invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9bFlPsrNQt1"
   },
   "source": [
    "Write (and verify) a function that performs scalar division with built-in handling of the edge case (i.e. return a value instead of just trapping the error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Cq2VAb8NQt1"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7Up8D6lNQt2"
   },
   "source": [
    "Apply the Pandas `isna` function to the following data objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_YvVav3NQt3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3 nan\n"
     ]
    }
   ],
   "source": [
    "x = 2.3\n",
    "y = np.nan\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAcf1FU1NQt4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJUM31pANQt5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. nan  3.]\n",
      " [ 4.  5. nan]]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LBgqnubNQt6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhFaZbzQNQt7"
   },
   "source": [
    "How is the pandas I/O parameter `na_values` used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mw-PvrTeNQt8"
   },
   "source": [
    "? ANSWER: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOW3ICgwNQt8"
   },
   "source": [
    "## Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZhJ9-XrNQt8"
   },
   "source": [
    "### Counts\n",
    "\n",
    "When there are categorical variables in a dataset we will want to know how many possible values there are in each column. (Nb. If the dataset is a sample of a larger one, our sample may not capture all possible values of every categorical.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RitKNRPCNQt8"
   },
   "source": [
    "How many (different) seasons are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqmE4OMsNQt9"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peDZrNJjNQt-"
   },
   "source": [
    "### Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIKyD5LHNQt-"
   },
   "source": [
    "Print the range of the `instant`, `dteday`, and `windspeed` columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVAOjyocNQt-"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5oDTJHoNQt_"
   },
   "source": [
    "Compute and print the overall minimum and maximum of the numeric data columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiIKiPT4NQuA"
   },
   "outputs": [],
   "source": [
    "bikes_min, bikes_max = (min(bikes.min()), max(bikes.max()))\n",
    "bikes_min, bikes_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyKKjxJoNQuB"
   },
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hxPA3sXNQuB"
   },
   "source": [
    "Pandas makes computing quantiles easy. This is how to get the median of a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1GLqWOoNQuB"
   },
   "outputs": [],
   "source": [
    "bikes['atemp'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBWCtrCrNQuD"
   },
   "source": [
    "Of course, the `quantiles` method can take a tuple as its argument. Compute the 10th, 25th, 50th, 75th, and 90th percentiles in one line of code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iu8bzEktNQuD"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJnCB_bqNQuF"
   },
   "source": [
    "### Cuts\n",
    "\n",
    "Sometimes we want to split the sample not by the quantiles of the distribution but by the range of the data. Let's take a closer look at `atemp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vn_cvvY-NQuF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bikes['atemp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ae7zUQp-NQuH",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>2012-02-16 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.30</td>\n",
       "      <td>15.150</td>\n",
       "      <td>70</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10416</th>\n",
       "      <td>2012-11-19 10:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.76</td>\n",
       "      <td>16.665</td>\n",
       "      <td>66</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>33</td>\n",
       "      <td>106</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>2011-09-09 10:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25.42</td>\n",
       "      <td>25.760</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>2011-02-11 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.12</td>\n",
       "      <td>15.910</td>\n",
       "      <td>21</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>12</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>2012-02-06 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>12.880</td>\n",
       "      <td>75</td>\n",
       "      <td>6.0032</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  season  holiday  workingday  weather   temp  \\\n",
       "6234   2012-02-16 00:00:00       1        0           1        2  12.30   \n",
       "10416  2012-11-19 10:00:00       4        0           1        2  14.76   \n",
       "3802   2011-09-09 10:00:00       3        0           1        2  25.42   \n",
       "679    2011-02-11 15:00:00       1        0           1        1  13.12   \n",
       "5996   2012-02-06 01:00:00       1        0           1        1   9.02   \n",
       "\n",
       "        atemp  humidity  windspeed  casual  registered  count  \n",
       "6234   15.150        70     8.9981       1          22     23  \n",
       "10416  16.665        66    16.9979      33         106    139  \n",
       "3802   25.760       100     0.0000       2          27     29  \n",
       "679    15.910        21    11.0014      12          62     74  \n",
       "5996   12.880        75     6.0032       0           6      6  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thwFHrthNQuJ"
   },
   "source": [
    "Suppose we decide to sort these values into 4 bins of equal width, but we want to apply the resulting groups to the entire DataFrame. Basically, we need to add a row label that indcates which bin each sample belongs in. Let's call this label \"atemp_level\", and use the `cut` method to populate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7mXBeXMNQuJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         (9.699, 18.638]\n",
      "1         (9.699, 18.638]\n",
      "2         (9.699, 18.638]\n",
      "3         (9.699, 18.638]\n",
      "4         (9.699, 18.638]\n",
      "               ...       \n",
      "10881    (18.638, 27.577]\n",
      "10882     (9.699, 18.638]\n",
      "10883     (9.699, 18.638]\n",
      "10884     (9.699, 18.638]\n",
      "10885     (9.699, 18.638]\n",
      "Name: atemp, Length: 10886, dtype: category\n",
      "Categories (5, interval[float64]): [(0.715, 9.699] < (9.699, 18.638] < (18.638, 27.577] < (27.577, 36.516] < (36.516, 45.455]]\n"
     ]
    }
   ],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 5)\n",
    "print(atemp_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vf3Q5vbQNQuL"
   },
   "source": [
    "What is `atemp_level`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhlx1W-VNQuL"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuDXdgfxNQuN"
   },
   "source": [
    "Here is a random sample of `atemp_level`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Qure0UbNQuN"
   },
   "outputs": [],
   "source": [
    "atemp_level.sample(5)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q59qWmqfNQuO"
   },
   "source": [
    "So, by default, `cut` produces labels that indicate the bin boundaries for each element in the series it was applied to. Usually, we will specify labels that are appropriate to the discretisation we are applying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYsD8ZwDNQuP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8619     hot\n",
       "6504    mild\n",
       "8290     hot\n",
       "383     cool\n",
       "7788    warm\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, object): ['cool' < 'mild' < 'warm' < 'hot']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4, labels = [\"cool\", \"mild\", \"warm\", \"hot\"])\n",
    "atemp_level.sample(5)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WD-3g9qLNQuQ"
   },
   "source": [
    "Incorporate the new `atemp_level` column into the `bikes` DataFrame and use it to count the number of \"mild\" `atemp` entries in `season` 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5fRRbXwNQuR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9373     mild\n",
       "2682     mild\n",
       "10786    cool\n",
       "5251     cool\n",
       "10433    cool\n",
       "Name: atemp, dtype: category\n",
       "Categories (2, object): ['cool' < 'mild']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "atemp_level = pd.cut(bikes['atemp'], bins = 2, labels = [\"cool\", \"mild\"]) # \"warm\", \"hot\", \"Very Hot\"])\n",
    "atemp_level.sample(5)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZN-0yDQNQuR"
   },
   "source": [
    "*Nb. The `atemp_level` variable we created is what the R language calls a \"factor\". Pandas has introduced a new data type called \"category\" that is similar to R's factors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxMDzgRWNQuS"
   },
   "source": [
    "# Synthetic Data\n",
    "\n",
    "Sometimes we may want to generate test data, or we may need to initalise a series, matrix, or data frame for input to an algorithm. Numpy has several methods we can use for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_W10uoBlNQuS"
   },
   "source": [
    "Execute the following, then check the shape and content of each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFR29OriNQuS"
   },
   "outputs": [],
   "source": [
    "# Creating arrays with initial values\n",
    "a = np.zeros((3))\n",
    "b = np.ones((1,3))\n",
    "c = np.random.randint(1,10,(2,3,4))   # randint(low, high, size)\n",
    "d = np.arange(4)\n",
    "e = np.array( [[1,2,3,4], [5,6,7,8]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) [0. 0. 0.]\n",
      "(1, 3) [[1. 1. 1.]]\n",
      "(2, 3, 4) [[[6 2 7 9]\n",
      "  [7 4 2 4]\n",
      "  [1 1 3 7]]\n",
      "\n",
      " [[7 8 3 5]\n",
      "  [7 5 4 5]\n",
      "  [6 9 2 2]]]\n"
     ]
    }
   ],
   "source": [
    "print (a.shape, a)\n",
    "print (b.shape, b)\n",
    "print (c.shape, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGrvvNNANQuT"
   },
   "outputs": [],
   "source": [
    "# Cleaning Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "e = np.array( [[1,2,3,4], [5,6,7,8]] )\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4) [[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "e = np.array( [[1,2,3,4], [5,6,7,8]] )\n",
    "print(e.shape, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JykYEjUHVppc"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "Load rock.csv and clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Song Clean ARTIST CLEAN Release Year  \\\n",
      "0                                Caught Up in You  .38 Special         1982   \n",
      "1                                    Fantasy Girl  .38 Special          NaN   \n",
      "2                                 Hold On Loosely  .38 Special         1981   \n",
      "3                          Rockin' Into the Night  .38 Special         1980   \n",
      "4                               Art For Arts Sake         10cc         1975   \n",
      "...                                           ...          ...          ...   \n",
      "2224                      She Loves My Automobile       ZZ Top          NaN   \n",
      "2225                            Tube Snake Boogie       ZZ Top         1981   \n",
      "2226                                         Tush       ZZ Top         1975   \n",
      "2227                                   TV Dinners       ZZ Top         1983   \n",
      "2228  WAITIN' FOR THE BUS/JESUS JUST LEFT CHICAGO       ZZ Top         1973   \n",
      "\n",
      "                                               COMBINED  First?  Year?  \\\n",
      "0                       Caught Up in You by .38 Special       1      1   \n",
      "1                           Fantasy Girl by .38 Special       1      0   \n",
      "2                        Hold On Loosely by .38 Special       1      1   \n",
      "3                 Rockin' Into the Night by .38 Special       1      1   \n",
      "4                             Art For Arts Sake by 10cc       1      1   \n",
      "...                                                 ...     ...    ...   \n",
      "2224                  She Loves My Automobile by ZZ Top       1      0   \n",
      "2225                        Tube Snake Boogie by ZZ Top       1      1   \n",
      "2226                                     Tush by ZZ Top       1      1   \n",
      "2227                               TV Dinners by ZZ Top       1      1   \n",
      "2228  WAITIN' FOR THE BUS/JESUS JUST LEFT CHICAGO by...       1      1   \n",
      "\n",
      "      PlayCount  F*G  \n",
      "0            82   82  \n",
      "1             3    0  \n",
      "2            85   85  \n",
      "3            18   18  \n",
      "4             1    1  \n",
      "...         ...  ...  \n",
      "2224          1    0  \n",
      "2225         32   32  \n",
      "2226        109  109  \n",
      "2227          1    1  \n",
      "2228          2    2  \n",
      "\n",
      "[2229 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "rock = pd.read_csv('rock.csv')\n",
    "print(rock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZQ4WoVYVppf"
   },
   "source": [
    "## Check Column Names\n",
    "\n",
    "Check column names and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-9a769a44a6f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'col' is not defined"
     ]
    }
   ],
   "source": [
    "for col in bikes.columns:\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KToV3ub3Vppg"
   },
   "source": [
    "## Replace Null Values With 0\n",
    "\n",
    "Check 'release' column whether this column have any null value or not. Replace null value with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQ2GyN7MVpph"
   },
   "source": [
    "## Check Datatypes of Dataset\n",
    "\n",
    "Check datatypes of the dataset. Is there any column which should be int instead of object? Fix the column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCzoReoXVpph"
   },
   "source": [
    "## Check Min, Max of Each Column\n",
    "\n",
    "Is there any illogical value in any column? How can we fix that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzJieuuyVppi"
   },
   "source": [
    "## Write Some Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2jYAjnOVVppi"
   },
   "source": [
    "## Write a function that will take a row of a DataFrame and print out the song, artist, and whether or not the release date is < 1970"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tk1XfgtkVppj"
   },
   "source": [
    "## Write a function that converts cells in a DataFrame to float and otherwise replaces them with np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEIsPER2Vppj"
   },
   "source": [
    "## Apply these functions to your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jz86dxCFVppk"
   },
   "source": [
    "## Describe the new float-only DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2asO3_lDFm8"
   },
   "source": [
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlasiTKgDGdA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Q0G5PtA2NQtC",
    "pTkOz1KsNQtK",
    "jS7P3oXQNQtL",
    "kGgcXCzyNQtN",
    "CaWhHAk9NQtQ",
    "ppLnAmKVNQtQ",
    "Kmjox61xNQtW",
    "JZhJ9-XrNQt8",
    "peDZrNJjNQt-",
    "OyKKjxJoNQuB",
    "EJnCB_bqNQuF"
   ],
   "name": "IOD_Lab 3.1.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
